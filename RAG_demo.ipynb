{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Demo (24summer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade pip, restart the kernel\n",
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restart the kernel after installing\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup the environment\n",
    "We use two Microsoft Azure API\n",
    "- Azure AI Search\n",
    "- Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import base64\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import *\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "import openai\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Environment settings from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Azure AI Search Index Settings\n",
    "service_endpoint = f\"{os.getenv('AZURE_SEARCH_SERVICE_ENDPOINT')}\"\n",
    "index_creds = AzureKeyCredential(os.getenv(\"AZURE_SEARCH_INDEX_KEY\"))\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "\n",
    "## Create a client for querying the index\n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=index_creds)\n",
    "## Create an index\n",
    "index_client = SearchIndexClient(service_endpoint, index_creds)\n",
    "\n",
    "# Azure Openai Settings\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.azure_endpoint = os.getenv(\"OPENAI_API_ENDPOINT\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "\n",
    "azure_openai_client = AzureOpenAI(\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\"),\n",
    "    api_version = os.getenv(\"OPENAI_API_VERSION\"),\n",
    "    azure_endpoint = os.getenv(\"OPENAI_API_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Search Index\n",
    "`name`: a unique name for the Index.\n",
    "- Think of the index as a **directory**/**folder**\n",
    "\n",
    "`fields`: a list of fields that will be fed into the index.\n",
    "- Think of a field as a **tag**\n",
    "- *MUST CONTAIN A KEY FIELD:* string field, as the unique **identifier** (An ID to each document stored with the index). Document IDs are case sensitive**\n",
    "- `SimpleField`\n",
    "- `SearchableField` must have a specified analyzer\n",
    "- `SearchField`\n",
    "\n",
    "`vector_search`: the vector search method for the index.\n",
    "\n",
    "Note: Every Index should have a different name. So re-running this block may lead to error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\n",
    "    SimpleField(name=\"id\", type=\"Edm.String\", key=True), # The Key Field\n",
    "    SearchableField(name=\"content\", type=\"Edm.String\", analyzer_name=\"standard.lucene\"),\n",
    "    SearchField(name=\"embedding\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),  \n",
    "                hidden=False, searchable=True, filterable=False, sortable=False, facetable=False,\n",
    "                vector_search_dimensions=1536, vector_search_profile_name=\"my-vector-config\"),\n",
    "    SimpleField(name=\"sourcepage\", type=\"Edm.String\", filterable=True, facetable=True),\n",
    "    SimpleField(name=\"sourcefile\", type=\"Edm.String\", filterable=True, facetable=True),\n",
    "]\n",
    "\n",
    "index = SearchIndex(\n",
    "    name=index_name, \n",
    "    fields=fields,    \n",
    "    vector_search=VectorSearch(\n",
    "        profiles=[VectorSearchProfile(\n",
    "            name=\"my-vector-config\",\n",
    "            algorithm_configuration_name=\"my-hnsw\")\n",
    "        ],\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(name=\"my-hnsw\")\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "result = index_client.create_index(index)\n",
    "# result = client.create_or_update_index(index, allow_index_downtime=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Index the document\n",
    "Think of this as Slicing the documents.\n",
    "\n",
    "To test out your own PDF docs, add to `data` folder and change the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"./data/\" + \"The_Innovation_Wings.pdf\" #Change to name of your file (make sure the file name does not include any space)\n",
    "\n",
    "def compute_embedding(text, model=\"textembedding\"): # model=[Deployment Name], DONOT change this\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return azure_openai_client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "offset = 0       #The character count from the start of the document\n",
    "page_map = []    #List of tuples: (page_num, offset, page_text)\n",
    "\n",
    "print(f\"Extracting text from '{filename}' using PdfReader\")\n",
    "\n",
    "reader = PdfReader(filename)\n",
    "pages = reader.pages\n",
    "for page_num, p in enumerate(pages):\n",
    "    page_text = p.extract_text()\n",
    "    page_map.append((page_num, offset, page_text))\n",
    "    offset += len(page_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SECTION_LENGTH = 1000\n",
    "SENTENCE_SEARCH_LIMIT = 100\n",
    "SECTION_OVERLAP = 100\n",
    "\n",
    "\n",
    "def filename_to_id(filename): \n",
    "    filename_ascii = re.sub(\"[^0-9a-zA-Z_-]\", \"_\", filename)\n",
    "    filename_hash = base64.b16encode(filename.encode('utf-8')).decode('ascii')\n",
    "    return f\"file-{filename_ascii}-{filename_hash}\"\n",
    "\n",
    "def split_text(page_map):\n",
    "    SENTENCE_ENDINGS = [\".\", \"!\", \"?\"]\n",
    "    WORDS_BREAKS = [\",\", \";\", \":\", \" \", \"(\", \")\", \"[\", \"]\", \"{\", \"}\", \"\\t\", \" \"]\n",
    "\n",
    "    def find_page(offset):\n",
    "        l = len(page_map)\n",
    "        for i in range(l - 1):\n",
    "            if offset >= page_map[i][1] and offset < page_map[i + 1][1]:\n",
    "                return i\n",
    "        return l - 1\n",
    "\n",
    "    all_text = \"\".join(p[2] for p in page_map)\n",
    "    length = len(all_text)\n",
    "    start = 0\n",
    "    end = length\n",
    "    while start + SECTION_OVERLAP < length:\n",
    "        last_word = -1\n",
    "        end = start + MAX_SECTION_LENGTH\n",
    "\n",
    "        if end > length:\n",
    "            end = length\n",
    "        else:\n",
    "            # Try to find the end of the sentence\n",
    "            while end < length and (end - start - MAX_SECTION_LENGTH) < SENTENCE_SEARCH_LIMIT and all_text[end] not in SENTENCE_ENDINGS:\n",
    "                if all_text[end] in WORDS_BREAKS:\n",
    "                    last_word = end\n",
    "                end += 1\n",
    "            if end < length and all_text[end] not in SENTENCE_ENDINGS and last_word > 0:\n",
    "                end = last_word # Fall back to at least keeping a whole word\n",
    "        if end < length:\n",
    "            end += 1\n",
    "\n",
    "        # Try to find the start of the sentence or at least a whole word boundary\n",
    "        last_word = -1\n",
    "        while start > 0 and start > end - MAX_SECTION_LENGTH - 2 * SENTENCE_SEARCH_LIMIT and all_text[start] not in SENTENCE_ENDINGS:\n",
    "            if all_text[start] in WORDS_BREAKS:\n",
    "                last_word = start\n",
    "            start -= 1\n",
    "        if all_text[start] not in SENTENCE_ENDINGS and last_word > 0:\n",
    "            start = last_word\n",
    "        if start > 0:\n",
    "            start += 1\n",
    "\n",
    "        section_text = all_text[start:end]\n",
    "        yield (section_text, find_page(start))\n",
    "\n",
    "        last_table_start = section_text.rfind(\"<table\")\n",
    "        if (last_table_start > 2 * SENTENCE_SEARCH_LIMIT and last_table_start > section_text.rfind(\"</table\")):\n",
    "            # If the section ends with an unclosed table, we need to start the next section with the table.\n",
    "            # If table starts inside SENTENCE_SEARCH_LIMIT, we ignore it, as that will cause an infinite loop for tables longer than MAX_SECTION_LENGTH\n",
    "            # If last table starts inside SECTION_OVERLAP, keep overlapping\n",
    "            start = min(end - SECTION_OVERLAP, start + last_table_start)\n",
    "        else:\n",
    "            start = end - SECTION_OVERLAP\n",
    "        \n",
    "    if start + SECTION_OVERLAP < end:\n",
    "        yield (all_text[start:end], find_page(start))\n",
    "\n",
    "# Organizing documents to upload to the Index\n",
    "sections = []\n",
    "file_id = filename_to_id(filename)\n",
    "for i, (content, pagenum) in enumerate(split_text(page_map)):\n",
    "    section = {\n",
    "        \"id\": f\"{file_id}-page-{i}\",\n",
    "        \"content\": content,\n",
    "        \"embedding\": compute_embedding(content),\n",
    "        \"sourcepage\": os.path.splitext(os.path.basename(filename))[0] + f\"-{pagenum + 1}\",\n",
    "        \"sourcefile\": filename\n",
    "    }\n",
    "    sections.append(section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "batch = []\n",
    "#index 1000 sections at a time\n",
    "for s in sections:\n",
    "    batch.append(s)\n",
    "    i += 1\n",
    "    if i % 1000 == 0:\n",
    "        results = search_client.upload_documents(documents=batch)\n",
    "        succeeded = sum([1 for r in results if r.succeeded])\n",
    "        print(f\"\\tIndexed {len(results)} sections, {succeeded} succeeded\")\n",
    "        batch = []\n",
    "        \n",
    "#index the remaining sections\n",
    "if len(batch) > 0:\n",
    "    results = search_client.upload_documents(documents=batch)\n",
    "    succeeded = sum([1 for r in results if r.succeeded])\n",
    "    print(f\"\\tIndexed {len(results)} sections, {succeeded} succeeded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have completed all the Preparations for RAG. \n",
    "\n",
    "We have built an AI search index \\(database\\) for **Retrieving relevant information**, which will be used in Section 5.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Try Out RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT is implemented for **Text Generation**.\n",
    "\n",
    "Test out Section 5.1 first to see what it can do!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0 **DEMO:** ChatGPT on its own \\(Without RAG\\)\n",
    "Try asking ChatGPT some questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the query to what you want to ask chatGPT\n",
    "query = \"What is the capital city of India?\"\n",
    "\n",
    "messages = [\n",
    "    {'role' : 'user', 'content' : query }\n",
    "]\n",
    "\n",
    "chat_completion = openai.chat.completions.create(\n",
    "    model=\"summer\", # Do not edit this. model=\"deployment_name\"\n",
    "    messages=messages, \n",
    "    temperature=0.7, \n",
    "    max_tokens=1024, \n",
    "    n=1)\n",
    "\n",
    "chat_content = chat_completion.choices[0].message.content\n",
    "chat_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Modify the role of ChatGPT through prompts. You can:\n",
    "- Add some system message\n",
    "- Add few shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the query to what you want to ask chatGPT\n",
    "query = \"Write a poem about university life\"\n",
    "\n",
    "#change the systemMessage to how you want chatGPT to behave\n",
    "systemMessage = '''You are a Shakespearean writing assistant who speaks in a Shakespearean style. \n",
    "                    You help people come up with creative ideas and content like stories, poems, and songs that use Shakespearean style of writing style, including words like \"thou\" and \"hathâ€.\n",
    "                    Here are some example of Shakespeare's style:\n",
    "                    - Romeo, Romeo! Wherefore art thou Romeo?\n",
    "                    - Love looks not with the eyes, but with the mind; and therefore is winged Cupid painted blind.\n",
    "                    - Shall I compare thee to a summer's day? Thou art more lovely and more temperate.'''\n",
    "\n",
    "messages = [\n",
    "    {'role' : 'system', 'content' : systemMessage},\n",
    "    #change the content here to your example question\n",
    "    {'role' : 'user', 'content' : 'Please write a short text turning down an invitation to dinner.'},\n",
    "    #change the content here to your example answer\n",
    "    {'role' : 'assistant', 'content' : '''Dearest,\n",
    "                                        Regretfully, I must decline thy invitation.\n",
    "                                        Prior engagements call me hence. Apologies.'''},\n",
    "    {'role' : 'user', 'content' : query }\n",
    "]\n",
    "\n",
    "chat_completion = openai.chat.completions.create(\n",
    "    model=\"summer\", # Do not edit this. model=\"deployment_name\"\n",
    "    messages=messages, \n",
    "    temperature=0.7, \n",
    "    max_tokens=1024, \n",
    "    n=1)\n",
    "\n",
    "chat_content = chat_completion.choices[0].message.content\n",
    "print(chat_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Implementing a RAG model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain related information using Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is SIG?\" #your query keywords\n",
    "query_vector = compute_embedding(query)\n",
    "\n",
    "def nonewlines(s: str) -> str:\n",
    "    return s.replace(' ', ' ').replace('\\r', ' ')\n",
    "\n",
    "r = search_client.search(\n",
    "    search_text=None,\n",
    "    top=3,\n",
    "    vector_queries=[VectorizedQuery(\n",
    "        vector=query_vector,\n",
    "        fields=\"embedding\"\n",
    "    )]\n",
    ")\n",
    "\n",
    "results = [doc[\"sourcepage\"] + \": \" + nonewlines(doc[\"content\"]) for doc in r]\n",
    "\n",
    "for result in r:\n",
    "    print(\"Source: \" + result[\"sourcepage\"])\n",
    "    print(nonewlines(result[\"content\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query GPT with **Query** + **Retrieved Information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the systemMessage to how you want chatGPT to behave\n",
    "systemMessage = \"\"\"AI Assistant that helps user to answer questions from sources provided. Be brief in your answers.\n",
    "                    Answer ONLY with the facts listed in the list of sources below. \n",
    "                    If there isn't enough information below, say you don't know. Do not generate answers that don't use the sources below. \n",
    "                    Each source has a name followed by colon and the actual information, always include the source name for each fact you use in the response. \n",
    "                    Use square brackets to reference the source, e.g. [info1.txt]. Don't combine sources, list each source separately, e.g. [info1.txt][info2.pdf].\n",
    "                \"\"\"\n",
    "\n",
    "messages = [\n",
    "    {'role' : 'system', 'content' : systemMessage},\n",
    "    {'role' : 'user', 'content' : query + \"   Source:\" + \" \".join(results)}\n",
    "]\n",
    "\n",
    "chat_completion = openai.chat.completions.create(\n",
    "    model=\"summer\", # Do not edit this. model=\"deployment_name\"\n",
    "    messages=messages, \n",
    "    temperature=0.7, \n",
    "    max_tokens=1024, \n",
    "    n=1)\n",
    "\n",
    "chat_content = chat_completion.choices[0].message.content\n",
    "print(chat_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aisearch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
